{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import py_midicsv as pm\n",
    "from midi2img import midi2image\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "    \n",
    "MIDI_PATH = \"../midi_files\"\n",
    "IMGS_PATH = \"../img_files\"\n",
    "DATA_PATH = \"../dataset\"\n",
    "DATA_PIXELS = \"pixels.npy\"\n",
    "DATA_IMGS = \"imgs.pickle\"\n",
    "IMG_WIDTH = 106\n",
    "IMG_HEIGHT = 106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 292 midi files\n"
     ]
    }
   ],
   "source": [
    "midi_files = glob.glob(os.path.join(MIDI_PATH, \"*mid\"))\n",
    "midis = []\n",
    "for midi in midi_files:\n",
    "    midis.append(midi)\n",
    "print(f\"There are {len(midis)} midi files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert MiDi files to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292\r"
     ]
    }
   ],
   "source": [
    "os.chdir(IMGS_PATH) # sets the target folder for the images\n",
    "midis_len = len(midis)\n",
    "print(f\"{midis_len} midi files found\")\n",
    "for i, midi in enumerate(midis):\n",
    "    print(f\"{i+1}/{midis_len}\", end='\\r')\n",
    "    try:\n",
    "        midi2image(midi)\n",
    "    except KeyboardInterrupt as KI:\n",
    "        raise KI\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating image from {midi}\")\n",
    "        raise e\n",
    "print(f\"{midis_len} midi files converted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert images to required size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5396 image files found\n",
      "5396 image files processed\n"
     ]
    }
   ],
   "source": [
    "midi_images = glob.glob(os.path.join(IMGS_PATH, \"*.png\"))\n",
    "midi_images_len = len(midi_images)\n",
    "\n",
    "print(f\"{midi_images_len} image files found\")\n",
    "\n",
    "for i, image in enumerate(midi_images):\n",
    "    print(f\"{i+1}/{midi_images_len}\", end='\\r')\n",
    "    try:\n",
    "        img = Image.open(image)\n",
    "        img = img.resize((IMG_WIDTH, IMG_HEIGHT), Image.ANTIALIAS)\n",
    "        img.save(image)\n",
    "    except KeyboardInterrupt as KI:\n",
    "        raise KI\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image}\")\n",
    "        raise e\n",
    "print(f\"{midi_images_len} image files processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5396 image files found. Converting into np array\n",
      "5396 image files converted\n",
      "\n",
      "dataset : (5396, 106, 106, 1)\n",
      "imgaes : 5396\n"
     ]
    }
   ],
   "source": [
    "image_files = glob.glob(os.path.join(IMGS_PATH, \"*.png\"))\n",
    "images_len = len(image_files)\n",
    "\n",
    "print(f\"{images_len} image files found. Converting into np array\")\n",
    "\n",
    "def access_imgages(length):\n",
    "    pixels = [] # to store pixel values\n",
    "    imgs = []   # to store images\n",
    "    for i in range(length):\n",
    "        print(f\"{i+1}/{length}\", end='\\r')\n",
    "        image = image_files[i]\n",
    "        try:\n",
    "            img = Image.open(image)\n",
    "            img = img.convert('1')\n",
    "            \n",
    "            pix = np.array(img.getdata())\n",
    "            pix = pix.astype('float32')\n",
    "            pix /= 255.0\n",
    "\n",
    "            pixels.append(pix.reshape(IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "            imgs.append(img)\n",
    "        except KeyboardInterrupt as KI:\n",
    "            raise KI\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image}\")\n",
    "            raise e\n",
    "\n",
    "    print(f\"{length} image files converted\")\n",
    "    return np.array(pixels), imgs\n",
    "\n",
    "\n",
    "pixels, imgs = access_imgages(len(image_files))\n",
    "print(f\"\\ndataset : {pixels.shape}\")\n",
    "print(f\"imgaes : {len(imgs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(pixels, imgs):\n",
    "    # save pixels np array\n",
    "    np.save(os.path.join(DATA_PATH, DATA_PIXELS), pixels)\n",
    "\n",
    "    # save imgs list\n",
    "    import pickle\n",
    "    saveFile = open(os.path.join(DATA_PATH, DATA_IMGS), 'wb')\n",
    "    pickle.dump(imgs, saveFile)\n",
    "    saveFile.close()\n",
    "\n",
    "def load_dataset():\n",
    "    # load np array into pixels\n",
    "    pixels = np.load(os.path.join(DATA_PATH, DATA_PIXELS))\n",
    "\n",
    "    import pickle\n",
    "    saveFile = open(os.path.join(DATA_PATH, DATA_IMGS), 'rb')\n",
    "    imgs = pickle.load(saveFile)\n",
    "    saveFile.close()\n",
    "\n",
    "    return pixels, imgs\n",
    "\n",
    "# save dataset\n",
    "save_dataset(pixels, imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the pixel values are all normalized between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values are normalized\n"
     ]
    }
   ],
   "source": [
    "uniqueVals = np.unique(pixels)\n",
    "if(uniqueVals.shape[0] == 2 and uniqueVals[0] == 0 and uniqueVals[1] == 1):\n",
    "    print('Pixel values are normalized')\n",
    "else:\n",
    "    raise Exception(\"Pixel values have not been normalized to 0 and 1 in pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 07:16:10.206842: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/\n",
      "2022-06-13 07:16:10.206894: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":/lib/\n",
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 07:16:12.846291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-13 07:16:12.846711: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/\n",
      "2022-06-13 07:16:12.846954: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/\n",
      "2022-06-13 07:16:12.847006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/\n",
      "2022-06-13 07:16:12.863323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/\n",
      "2022-06-13 07:16:12.863393: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/\n",
      "2022-06-13 07:16:12.863653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/\n",
      "2022-06-13 07:16:12.863680: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "print(os.environ[\"LD_LIBRARY_PATH\"])\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape = (106, 106, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 53 * 53\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((53, 53, 128)))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2DTranspose(1024, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2D(1, (7,7) , padding='same',activation = 'sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to generate parameters and data for the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random points from the dataset for the discriminator\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "# generate random input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# generate fake input using the generator for the discriminator\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=51, n_batch=10):\n",
    "    print(f\"Starting training\")\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        print(f\"{i}/{n_epochs} epochs\")\n",
    "\n",
    "        for j in range(bat_per_epo):\n",
    "            print(f\"{j}/{bat_per_epo} batch\")\n",
    "\n",
    "            # generate fake and real samples for discriminator\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            \n",
    "            # train discriminator on fake + real samples\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "\n",
    "            # generate noise for generator\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            \n",
    "            # train generator on noice\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            \n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "    print('\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 07:16:28.091649: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/prithivi/.local/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2022-06-13 07:16:28.211013: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 143820800 exceeds 10% of free system memory.\n",
      "2022-06-13 07:16:28.268617: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 143820800 exceeds 10% of free system memory.\n",
      "2022-06-13 07:16:28.332663: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 143820800 exceeds 10% of free system memory.\n",
      "2022-06-13 07:16:28.468537: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2022-06-13 07:16:28.488316: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "0/51 epochs\n",
      "0/20 batch\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "\n",
    "train(g_model, d_model, gan_model, np.array(pixels), latent_dim)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
